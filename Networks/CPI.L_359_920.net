FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 16 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.73046767858017460640e+02) (1, 4.76942632125391412501e+02) (2, 7.59105088233229480466e+02) (3, 1.38481406639671774883e+02) (4, -1.50000000000000000000e+03) (5, 1.87531836312571527969e+02) (6, -1.47586921805220617898e+03) (7, 6.02180100788497497888e+02) (0, 1.50000000000000000000e+03) (1, -1.11028030249500898208e+03) (2, -1.50000000000000000000e+03) (3, 6.52981336945335328892e+02) (4, -1.50000000000000000000e+03) (5, 2.53356177308890465838e+02) (6, 2.25326405157796841650e+02) (7, 1.28324289338492832258e+02) (0, 1.90619224003646479559e+02) (1, -1.27336612999196375995e+02) (2, -3.05331517950152203866e+02) (3, -1.00496577094530880458e+03) (4, 1.28082630504465350896e+03) (5, -7.18344067493528541490e+02) (6, 6.69688464067616564535e+02) (7, -5.79337789309813388172e+02) (0, -1.26946741760433248203e+01) (1, -1.27843815219705874142e+02) (2, -1.00231560959399143940e+03) (3, -5.90893591576451555625e+01) (4, -1.24743673148286165997e+03) (5, 2.91379974874581478161e+02) (6, -1.34417006960529874959e+02) (7, 8.18546863738429919977e+02) (0, -1.50000000000000000000e+03) (1, -1.47184435767649597437e+03) (2, 1.50000000000000000000e+03) (3, 9.29933522543272601979e+02) (4, 1.50000000000000000000e+03) (5, 1.50000000000000000000e+03) (6, -1.33866469267095703799e+03) (7, -1.48460116317986989998e+03) (0, 2.53835868513254609979e+02) (1, -2.44003076696539807244e+02) (2, -1.26697936562816366290e+02) (3, 3.70147071829246328889e+02) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -1.32048891245353587465e+02) (7, 6.04423385902332370279e+02) (0, -6.70308993227309368734e+00) (1, 5.00241638671896069468e+01) (2, 1.01050487235378966488e+02) (3, -2.76595461902907509000e+01) (4, 1.10105093114912946817e+02) (5, -2.19947088561982937449e+01) (6, -2.26264996002579117373e+01) (7, -8.40058921096932067485e+01) (0, 5.58168952704734024906e+01) (1, -3.40471724184817574610e+01) (2, -5.56307771356066496082e+01) (3, 3.82703590543955129988e+01) (4, 4.95414985967054022353e+01) (5, -1.78072173861357683222e+01) (6, -3.76099826548097340151e+01) (7, -2.42242792940918194589e+00) (0, -6.00986338166953828477e+01) (1, 1.00421386040130002471e+02) (2, 4.02770147040882363854e+02) (3, 2.32659548902258080716e+02) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, 6.99225233709083369149e+01) (7, -4.55705734462628527126e+02) (0, -6.41437379349734815293e+00) (1, 9.84643332562005468844e+00) (2, 5.94028172784081220925e+00) (3, 4.94149635273471066199e+00) (4, -2.60154512025298210176e+01) (5, -2.78558930500913106698e+01) (6, 2.13390297601843581532e+00) (7, 1.06369438364030943767e+00) (0, -4.77176011037804755688e+02) (1, -1.07931360597499576670e+02) (2, -8.61515169817726814472e+02) (3, -1.02916622027421726671e+03) (4, 4.02314049300152476007e+02) (5, 8.81783513435749881637e+01) (6, 4.90607615427671532871e+02) (7, 1.36577584928396959185e+02) (0, 8.62845923787092146995e+02) (1, -1.08223849662015891226e+03) (2, 1.30758617417487107559e+03) (3, -7.60514273199449007734e+02) (4, -1.50000000000000000000e+03) (5, 1.38940046243954526517e+02) (6, 1.50000000000000000000e+03) (7, -4.74316146948698644792e+01) (0, -1.29001596364384141680e+02) (1, -1.51983254697706911429e+02) (2, -1.16307743648623457489e+02) (3, -3.86104661263368257096e+02) (4, 7.19093268687121621952e+02) (5, -5.08587301212521140314e+02) (6, 3.69729245448333870172e+02) (7, -1.67254370131725522697e+02) (0, 1.33554498525156702726e+02) (1, -4.13670785373815306230e+01) (2, 3.60932207642480477716e+02) (3, 4.80138185769166511818e+02) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -2.38940480072884980700e+02) (7, 3.37222461636980995081e+02) (0, 2.73250845069692118727e+01) (1, -2.04102109880748763260e+01) (2, -1.39150474488609798840e+01) (3, 4.08884868445651292745e+01) (4, -1.79556774517022574855e+01) (5, -5.29487549629880493995e+00) (6, -1.66319385378412185617e+01) (7, -6.74746902386805569307e+00) (8, 1.10842294002317953705e+00) (9, 6.84197503602761436525e-01) (10, -1.05485057473902821279e+00) (11, 5.92819079613805666185e+00) (12, -6.30188625386247980309e-01) (13, 1.17677220002119664599e+00) (14, 9.68210716476343713488e-01) (15, 3.55867409797840927865e+00) (16, 1.74893526532073440016e+00) (17, -3.45770675548248984654e+00) (18, -8.08111289909732910530e+00) (19, 2.77526842154161546006e+00) (20, -8.77262129412161084652e-01) (21, 2.39228259930072928441e+00) (22, -3.66206924070972883456e+00) (23, -3.56474336913707823271e+00) 
