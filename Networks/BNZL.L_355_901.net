FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 10 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+03) (1, -1.47453462579419169742e+03) (2, -2.73584418750581846780e+02) (3, 1.50000000000000000000e+03) (4, 1.45088566000953665025e+03) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, 3.45588218462239581186e+02) (0, -1.02251717659673992955e+01) (1, 1.23148073424049293578e+01) (2, -3.38804981649314669312e+01) (3, 2.15374803138907680022e+01) (4, -1.15189313932521422146e+01) (5, -1.23439177919963309904e+01) (6, 1.54812941711426024227e+01) (7, -4.45699983191442594688e+00) (0, -6.70046761127946410852e+00) (1, 5.59109516451981214402e+00) (2, -2.34879809140072133289e+01) (3, 1.12391486246356926415e+01) (4, -1.09622914157806565782e+01) (5, -1.16811991070881386889e+01) (6, 1.55203308587943134000e+01) (7, -2.80005214496556575909e+00) (0, 1.87056705804095287249e+02) (1, -2.59290259346988136713e+02) (2, 1.52001758154943701129e+02) (3, 4.28826526482589756029e+01) (4, -7.90433083096152433455e+00) (5, 1.93451758750026030498e+01) (6, -1.01379078772252483986e+02) (7, -3.17881707783515814469e+01) (0, 1.67489679167185592235e+01) (1, 9.66963614681884706670e+01) (2, 1.07159496065827628541e+01) (3, -4.71910644947019335405e+01) (4, 5.38919768137534589414e+01) (5, -8.42294115459935426315e+01) (6, -5.43850689129055098192e+01) (7, -1.26624025595557849755e+01) (0, -1.43855599861800214967e+02) (1, -8.22760715574390815163e+01) (2, 6.10124124328150116980e+01) (3, -1.53641882741233246179e+02) (4, -9.47552232008242611982e+01) (5, 1.43738761907918721761e+01) (6, -1.48782275543659039840e+02) (7, 1.45473900412536579552e+02) (0, 1.25908633563627574858e+02) (1, -4.16134410847865694905e+02) (2, 1.06166449015495754793e+03) (3, -1.48188185510148650792e+03) (4, -8.30424304966779686765e+02) (5, 1.50000000000000000000e+03) (6, 1.50000000000000000000e+03) (7, -1.39455656264677691070e+03) (0, -1.24330469751858728955e+02) (1, -1.25306153199673374843e+02) (2, -5.90986605093819321155e+02) (3, 1.50000000000000000000e+03) (4, -6.94467689054725042297e+02) (5, -1.50000000000000000000e+03) (6, -2.81449826474906501517e+02) (7, 1.04954454962050022004e+02) (0, 3.80979538587867860855e+00) (1, -3.44539686972370873264e+01) (2, 2.72072833799221314166e+01) (3, -9.39926874980731668074e+01) (4, -1.00184782064065529994e+02) (5, -5.74137761196056004565e+01) (6, 6.36309283758906403250e+01) (7, 2.23542042453406502034e+01) (8, -1.39939653793742535548e+00) (9, 1.22749078295825828633e+01) (10, -1.46272661268193804318e+01) (11, 1.37669777573470875076e+00) (12, 8.74318989303250471146e-01) (13, 1.17955041654684400498e+00) (14, 4.96017671565855189364e-01) (15, -5.00316978510773058275e-01) (16, 2.92860586619215368387e+00) (17, -5.47925326859746153474e-01) 
