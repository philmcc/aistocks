FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.09047805873440371016e+01) (1, -1.80449783053898869412e+02) (2, 5.20336350201868754084e+02) (3, 2.18778894764692381614e+02) (4, -1.25120783828727013542e+01) (5, 1.31853178621771917278e+03) (6, -1.50000000000000000000e+03) (7, -2.52423601095468143285e+02) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, 1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 5.66288081956645783066e+02) (6, -1.50000000000000000000e+03) (7, 1.18389907071114475201e+00) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, 1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 5.66288081956645783066e+02) (6, -1.50000000000000000000e+03) (7, -1.77250770325086492996e+00) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, 1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 5.66288081956645783066e+02) (6, -1.50000000000000000000e+03) (7, -1.99011654013032290855e+00) (0, 1.65542292557187060709e+01) (1, 8.73402770817132179104e+00) (2, 6.26773544626934437929e+01) (3, -9.93250312503163996780e+01) (4, -3.75065368955495870296e+01) (5, 3.29634237686555442437e+00) (6, -5.75292287934591684007e+00) (7, 1.84062802183600027206e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, 1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 5.66288081956645783066e+02) (6, -1.50000000000000000000e+03) (7, -5.18821057143603825423e-01) (0, 9.51070170828850436351e+00) (1, -1.55072577215951639573e+02) (2, -5.62603796833217444373e+01) (3, 1.35518681965592520555e+02) (4, -4.24146907695291162099e+01) (5, 3.83219223213781958748e+01) (6, 1.20615218765842335813e+01) (7, -5.31724452455199791956e+00) (0, -4.94943922018035031840e+00) (1, -3.80343908205880820717e+00) (2, -1.43142061935370392689e+01) (3, 2.67896554320448920805e+01) (4, 1.00373910509986643547e+01) (5, -1.08143330854100905292e+00) (6, -9.81500641350263935969e-01) (7, -2.81198755634459596209e+00) (0, -1.86871478674647626406e+01) (1, 2.38583855815218583984e+02) (2, 1.53762229833430922099e+02) (3, -2.82314604943838503459e+02) (4, 4.82022781496486132369e+01) (5, -9.82835534829582911698e+02) (6, -1.18226078038324970976e+02) (7, 7.07953905204087163838e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, 1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 5.66288081956645783066e+02) (6, -1.50000000000000000000e+03) (7, -3.02445990046915458294e+00) (8, 1.01357589177358109467e+00) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, 1.50000000000000000000e+03) (12, 4.86893766738221245305e+00) (13, 1.50000000000000000000e+03) (14, -5.20458542518279498879e-01) (15, 5.10771844502926430920e+00) (16, 6.41866214011843627674e-01) (17, 1.50000000000000000000e+03) (18, -5.68013670298666628611e+00) 
