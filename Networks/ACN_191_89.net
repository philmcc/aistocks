FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.70785411476757303717e+02) (1, -1.07403428417440613885e+03) (2, 3.22135957659548012089e+02) (3, -1.47724204310512874372e+02) (4, -7.16296283894924840752e+02) (5, 5.94318306791490044816e+02) (6, 1.16366081803967858832e+03) (7, -3.44835087088744174366e+00) (0, -3.66065031575830790445e+00) (1, -4.63927404329806858385e+00) (2, 1.01289799713813746251e+01) (3, -7.66527967858145053981e+00) (4, -1.14233387266090922196e+01) (5, 6.03417344091763396818e+00) (6, 1.43632895526442148082e+01) (7, -1.07622569536696821579e+00) (0, 6.54791585310383766227e+02) (1, -7.30060298412928204925e+02) (2, -3.32294791559155783034e+02) (3, 5.77906810204085445548e+02) (4, 2.29922315178616933906e+01) (5, -1.05811714594550699076e+03) (6, 6.75764517544988166264e+02) (7, -9.41626681748540050876e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -7.17089509296819073825e+02) (3, 2.83834482821214919568e+02) (4, -4.24831250783867744758e+02) (5, 1.33142419783692798774e+03) (6, 2.96057623746129536357e+02) (7, -6.95900727070193259038e+00) (0, 8.41036506444448583864e+00) (1, -5.39728826413670481621e-01) (2, 3.07207783393993629772e+01) (3, -4.04698402185471834969e+01) (4, 2.09668127949033911150e+00) (5, 4.19181773277417513146e-01) (6, -1.08599815777324941735e+01) (7, 2.49187986579613030003e+00) (0, -6.40808706749481757470e+02) (1, -3.96772492548129548595e+02) (2, -1.08668936099304531240e+02) (3, 3.06271102921090573545e+02) (4, 1.42331897308726269102e+02) (5, -1.50000000000000000000e+03) (6, 1.10150680853141034277e+03) (7, -2.34926225484696317380e+02) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, 1.48159666674244635942e+03) (0, 1.74203627078755403090e+01) (1, -8.92550548301286106323e+00) (2, -8.08361343391583453410e+00) (3, 8.40134053048628004490e+00) (4, 1.84608893433279597218e+01) (5, 7.25498014353917675123e+00) (6, -2.40166522958559163214e+01) (7, -4.82910236038402829184e-01) (0, 2.29720733251990374413e+01) (1, 4.55806921090623617943e+01) (2, -3.06651138014655100239e-01) (3, -7.99355879984187680520e+01) (4, 1.98001357107266890978e+01) (5, 1.07381009862913899156e+02) (6, -6.77688511681193830327e+01) (7, 4.24964917724893638251e+01) (0, 9.76773177554116300847e-01) (1, -3.61884279140302467237e-01) (2, -5.54554038084963085709e+00) (3, 5.47754718578079380364e+00) (4, 2.25041212440658977556e+00) (5, -1.22752257381867191377e+00) (6, -2.92023825015064986133e+00) (7, 1.21695816739363493753e+00) (8, -1.44057719591507815693e+00) (9, 2.81598744813015144928e+00) (10, -1.48744887160353944644e+00) (11, 8.31317437870255360188e-01) (12, 1.69104929097070577626e+00) (13, -1.77155413754575552510e+00) (14, 9.03214906446817011876e-01) (15, -1.92461992261902459234e+00) (16, -1.69646910963962960217e+00) (17, 6.37045713559417148275e+00) (18, -8.49311607840476434639e-01) (8, 1.28751099570656135640e+00) (9, -2.62739313795804729779e+00) (10, 1.70434628029370727198e+00) (11, -6.27870080266956009929e-01) (12, -1.68508886020424442087e+00) (13, 1.58413405596756295957e+00) (14, -2.31027663147282791289e-01) (15, 2.05753534030695917068e+00) (16, 1.68136684730564467394e+00) (17, -6.26238034670675514093e+00) (18, 3.05655849215273045516e+00) 
