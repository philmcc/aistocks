FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 16 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.29654296000052937643e+01) (1, -3.57809815675756439646e+01) (2, 1.08852490028485021867e+02) (3, -1.69757908737515208486e+02) (4, 2.61620649884908615945e+01) (5, 1.77778531766745651055e+00) (6, -1.19150564466701837318e+02) (7, 4.04266193148830836890e+01) (0, -1.36180781248969560693e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, 1.50000000000000000000e+03) (5, 9.69205216411075753058e+02) (6, -1.47837776120685498427e+03) (7, 9.42450364233838854489e+02) (0, -8.81521333378509666545e+02) (1, -1.49625031908760206534e+03) (2, 2.58290592477961126860e+02) (3, 1.50000000000000000000e+03) (4, 1.50000000000000000000e+03) (5, -1.49545882963724284309e+03) (6, -5.58771532512102226065e+02) (7, 1.50000000000000000000e+03) (0, 6.78631654901540173341e+02) (1, -3.59051244418314468021e+02) (2, 4.80608927504995904201e+02) (3, -9.36496189296564352844e+02) (4, 1.32321437623750739476e+02) (5, -1.50000000000000000000e+03) (6, -1.38253180056501804529e+02) (7, -1.14147768664537650807e+02) (0, -7.34755083993975176782e+02) (1, 3.94816839335912789011e+02) (2, 1.50100627047647805057e+02) (3, -1.60412938170485510625e+01) (4, -3.97116939127083355743e+02) (5, -1.84635734128433227852e+02) (6, 5.16679007225841246509e+02) (7, -2.15349269530717180032e+00) (0, -1.29046525573746362170e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -6.69327781914644333483e+02) (4, 1.50000000000000000000e+03) (5, 8.13948199204704678777e+02) (6, -1.47118842908590136176e+03) (7, 1.50000000000000000000e+03) (0, -8.61222346927148407758e+00) (1, 1.43649559263664230002e+02) (2, -6.83227544291904376195e+00) (3, -8.48310984564749617221e+01) (4, -2.47840023532624762481e+01) (5, 3.76014508727994751780e+01) (6, -8.41180300814972348178e+00) (7, -6.64469028609774881033e+01) (0, -5.23095368265603269720e+02) (1, -1.50000000000000000000e+03) (2, -1.26118342536596787795e+03) (3, -5.98449349128043081691e+02) (4, 1.50000000000000000000e+03) (5, -1.40229833983361163519e+03) (6, -9.48823302424970393076e+02) (7, 1.50000000000000000000e+03) (0, -1.46355724647631109292e+03) (1, -3.12996144796862438398e+02) (2, -1.25222486910290236040e+01) (3, 3.03907697507728073560e+02) (4, 1.50000000000000000000e+03) (5, 1.15931172993865766330e+03) (6, 3.42479629699564839029e+02) (7, 5.25968191237464793630e+02) (0, 1.99254480315436524052e+02) (1, 1.34626181075264046427e+01) (2, -7.92670039345910169004e+01) (3, 3.81067186403450023136e+02) (4, 8.14879717646382850660e+00) (5, -2.55689784056737146045e+00) (6, -2.26684299398146720250e+02) (7, -9.82400951336388743584e+01) (0, -1.39785059770559865200e+01) (1, 3.16532377099633137618e+01) (2, -1.70462026750545696530e+01) (3, 2.34058357701556722930e+01) (4, -4.82371490087905563371e+00) (5, 1.22538273788927898345e+00) (6, -3.91936152734833953559e+01) (7, 2.67962715621830405155e+01) (0, -2.02390703986780735590e+01) (1, 5.51739885272706160890e+01) (2, 9.08811719842996268426e+01) (3, -4.73643735842729256547e+01) (4, -3.23717495887743282879e+01) (5, -1.61934931858571964369e+01) (6, 4.35618598549676434573e+01) (7, -8.85424305516759435619e-01) (0, -8.63180005896347324779e+02) (1, -1.50000000000000000000e+03) (2, -1.49513578829370521817e+03) (3, -1.83686334105192315747e+02) (4, 1.50000000000000000000e+03) (5, 1.50000000000000000000e+03) (6, -1.16868695527877389395e+03) (7, 8.24900533277486033512e+02) (0, -2.91940619952383315194e+02) (1, 1.87752814519729781750e+02) (2, 1.54224937647132716023e+01) (3, 1.35816064858065089993e+02) (4, 7.70606127453225866475e+01) (5, -8.11708696663254016812e+01) (6, 1.91228407691671264956e+01) (7, -1.11356528632626762487e+02) (0, 1.25123657954946423843e+02) (1, -1.16744612037824182948e+02) (2, 2.21826090341517073057e+02) (3, -1.12274183644587743913e+01) (4, -9.79185549304066142895e+01) (5, 7.56942282181501440164e+01) (6, -8.32999895185178047541e+01) (7, -1.20493996134839818524e+02) (8, 1.25404403142350329148e+00) (9, -1.00709482579651909973e+00) (10, -9.32966786172641393549e-01) (11, -1.20481667133424430460e+00) (12, -4.60342545449355766696e-01) (13, -4.39032317455672504991e-01) (14, -1.31687665342084514464e+00) (15, -5.70046424866062495518e-01) (16, -5.88850763135789323499e-01) (17, -1.28587020986634414932e+00) (18, 6.65957150921904617036e+00) (19, -1.94131948075432125833e+00) (20, -8.07091445163465981416e-01) (21, 1.81626491330519357348e+00) (22, -6.05117502131369500162e-01) (23, -1.73149932911521098333e+00) 
