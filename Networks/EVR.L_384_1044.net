FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.75472696765655655327e+02) (1, -1.02442405403445206957e+01) (2, 6.47938253860822328534e+01) (3, 2.36043280752185786753e+01) (4, -1.14205351200140853507e+02) (5, 1.65861734109734925369e+02) (6, 7.50932270116014564110e+01) (7, -1.76918205412214675221e+01) (0, -1.60486308395241401570e+01) (1, 1.35454815188490851341e+01) (2, 3.74366712954632152588e+00) (3, -4.61981994960353858914e+00) (4, -3.34559700691615002910e+00) (5, 4.40678330163445863832e+00) (6, -5.58264510360693755331e+00) (7, -3.32327585708465989001e+00) (0, 7.63512497068672018941e+02) (1, 1.13598228230030372288e+03) (2, -8.06059376447737122362e+02) (3, 9.98428065518824610081e+02) (4, -1.38809371819570037587e+03) (5, 1.45445455101089805794e+03) (6, -1.50000000000000000000e+03) (7, -1.50000000000000000000e+03) (0, -2.11917352662613538428e+01) (1, 5.39820904122542088999e+00) (2, -3.75188139632251207445e+01) (3, 7.16538924829624761514e+01) (4, -1.70119185096419767156e+00) (5, -1.30739168204314415433e+00) (6, 1.68932150207507660866e+01) (7, -1.42722045872350609130e+01) (0, -1.31931923036972165164e+01) (1, 4.06256573690898825646e+00) (2, 8.12315601393003383635e+00) (3, -1.29079737696330765218e+00) (4, -2.49016849982248533735e+00) (5, 2.52886551592338815198e+00) (6, -1.13374435655535887868e+00) (7, -2.10840326025788105113e+00) (0, 4.97550065513130846284e+02) (1, -1.55767563325912050232e+02) (2, -7.35124029928479103546e+01) (3, 1.82684189591346211046e+02) (4, -4.88252047874370660452e+01) (5, 3.52286135322832421934e+02) (6, -1.92679066818202016975e+02) (7, -3.28850606182108663234e+02) (0, -6.73352031337473810879e+00) (1, 7.07718692950333849723e+00) (2, 6.17080524117945916629e+00) (3, -1.89091031394747566274e+00) (4, -7.56157628995849506737e+00) (5, 5.05389781357101108838e-01) (6, -4.63777505182130678207e+00) (7, 1.53304256664140114985e+00) (0, -4.14917603728364781546e+02) (1, -2.67428181657685286154e+02) (2, -2.29149016865408015065e+01) (3, 1.50000000000000000000e+03) (4, 1.50000000000000000000e+03) (5, 4.53658908268789730300e+02) (6, -5.75746638683377454981e+02) (7, -2.51606335960873963131e+02) (0, -5.77413149154021198228e+02) (1, -1.75425076236081423531e+02) (2, -9.64704456215152958976e+01) (3, -2.13664878534228449780e+02) (4, 2.51308613127080747063e+02) (5, 3.14227125496237931657e+02) (6, 5.29979761123097091513e+02) (7, 1.63055236808091166267e+02) (0, -4.13655896705857983875e+01) (1, 2.55530784041725311795e+01) (2, -9.92740217148849524165e+00) (3, 7.31640350343294265656e+00) (4, -1.12102181186956393333e+01) (5, -3.54756734465654011146e+00) (6, 1.26037506825156579993e+01) (7, 1.10905843089333870921e+01) (8, -9.48757731896906375546e-01) (9, -3.81661871555675302758e+00) (10, 6.90260224819689072184e-01) (11, -8.56702890523229898534e-01) (12, 4.20456310256824661309e+00) (13, 9.89089803915714549376e-01) (14, -1.91236975887577353994e+00) (15, 1.06486237987655774084e+00) (16, -9.99073373882122028888e-01) (17, 1.27792948459835509212e+00) (18, -4.23581723134691279231e-01) 
