FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 16 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.32571716533179731479e-02) (1, -3.97693463008008257775e-02) (2, 3.76511138886379201351e-02) (3, 7.81803992119490809287e-02) (4, 5.93433451368413009130e-02) (5, -4.00816319895033745802e-03) (6, 4.92214461672521447211e-02) (7, 5.41690701308707792117e-02) (0, -3.92490926459296354811e-02) (1, -5.34699315722276385943e-02) (2, -3.07101232850569907940e-02) (3, -8.37323489037505863664e-02) (4, -8.15475932366787198413e-02) (5, 9.34370323968981286722e-02) (6, -5.45307887461898913029e-02) (7, 3.73061520018600142889e-02) (0, 6.75724293861154901020e-02) (1, -4.17053527825378203553e-02) (2, -9.74601881200102965197e-02) (3, -5.82322747741978452574e-03) (4, 7.29107005210325037625e-02) (5, -1.60526444733536874376e-02) (6, -6.08258394274985569883e-02) (7, -3.37242365252112749618e-02) (0, 1.26252352278714632949e-02) (1, -9.77746933367057424746e-03) (2, -1.93410343578611920723e-02) (3, -2.30870252190086971966e-02) (4, 5.79785527919017065757e-02) (5, 2.84067127429949092821e-02) (6, -5.22350005207210740799e-02) (7, -8.52786203515323859570e-02) (0, 8.86373679323101959504e-02) (1, 8.54161148580329654401e-02) (2, 9.29017803505328143565e-02) (3, 4.79807115790353844176e-02) (4, -1.85920498310334914027e-02) (5, 4.21232251208010985422e-02) (6, 2.14978021979004424447e-03) (7, 4.21588590131529925009e-02) (0, 8.86532950386895723938e-02) (1, 7.14396584248491728353e-02) (2, 5.84265116926507774298e-02) (3, -9.28942996881052529545e-02) (4, 6.48766894247634479109e-02) (5, -9.61042785436552332579e-02) (6, 4.44118538970031326296e-02) (7, 3.24491173207628255670e-02) (0, -3.78096298360769342284e-02) (1, 4.69516672671089554947e-02) (2, -7.33741116467730714046e-02) (3, -6.48989308051605429117e-02) (4, -6.91009786963608513277e-02) (5, -3.41999495841555159470e-02) (6, 1.37683425287655342162e-03) (7, 4.35242580216267313520e-02) (0, 5.60225825722900291903e-02) (1, 8.20358013851314737952e-02) (2, -7.95627686874980921683e-02) (3, 1.40011338740756163812e-02) (4, 1.04425126380102706314e-02) (5, -3.17977677181030399245e-02) (6, 2.87225151057916086583e-02) (7, -9.20120919795645864081e-04) (0, -4.63816542570539350199e-02) (1, 2.16242939662083036301e-02) (2, -5.29394108308763808313e-02) (3, 3.50262974020286929622e-02) (4, -3.62524824031067172125e-02) (5, 4.92103709721620416473e-02) (6, -2.28148449818021750723e-02) (7, -4.75991887614009984153e-02) (0, 2.06500279068950950978e-02) (1, -6.43883347792675170274e-02) (2, -4.04934869593901389240e-02) (3, -1.44732841584575763760e-02) (4, -6.04926118328066309004e-02) (5, -9.60816345525031256791e-02) (6, -8.20241683278108701938e-02) (7, 1.69775982123255425593e-03) (0, 5.08700342047219492003e-02) (1, -5.53982784844678291525e-02) (2, 3.67988305061881237901e-02) (3, 8.17690570916094761067e-02) (4, 1.04017735146250331346e-02) (5, -6.18243367310514421731e-02) (6, 2.52933136231200880739e-02) (7, -3.35756454032010570598e-02) (0, -7.97885368360360808238e-02) (1, 4.57305465188703810786e-02) (2, 8.04254900541229444944e-02) (3, 3.06539772920903091924e-02) (4, -8.60672226893487712918e-02) (5, 9.14800366979842682902e-03) (6, -7.02661451178214491176e-02) (7, -3.24488754562865938658e-02) (0, -6.92277038541093958646e-02) (1, -2.32055543654494586536e-02) (2, -9.74225794512417614390e-02) (3, -5.48018467396772790412e-03) (4, -7.39951848834035363911e-02) (5, -2.02374229429278171266e-02) (6, 4.69206280547473930653e-02) (7, 4.66548445136076780915e-02) (0, 1.53742437679207852308e-02) (1, -9.35728603947588721823e-02) (2, -6.78184410418337657589e-02) (3, 5.48816334252302737151e-02) (4, -8.96544933640136126884e-02) (5, -4.98426078795285096290e-02) (6, -4.34206082436532914137e-02) (7, 6.12155423308244558966e-02) (0, -5.24088478074796054740e-03) (1, 9.33782237526509517611e-02) (2, 4.29845979323178126186e-02) (3, -9.48391127562390467975e-02) (4, -6.84461143753843509474e-02) (5, -3.17220898415459598429e-02) (6, -2.84147566693239844726e-02) (7, -4.82346497213043123864e-02) (8, -8.59915448127916981491e-02) (9, -4.79892681053171663019e-02) (10, 8.24193291540343819790e-02) (11, -7.20587660120243500561e-02) (12, 6.11587370545973799119e-02) (13, -8.78468174539032004011e-02) (14, -4.50763988506257262667e-03) (15, 9.19310347837363761592e-02) (16, -1.10523703292365396700e-02) (17, -1.93021784618821468094e-03) (18, -1.35491513803474780686e-02) (19, 1.49524462774760433237e-02) (20, 7.78323607010000806383e-02) (21, -6.66285248157162113269e-02) (22, -3.83927106059001391203e-02) (23, -6.79339702119524657675e-03) (8, -6.02013837203589502467e-02) (9, -6.21115015761777855552e-03) (10, -5.19117650860810922464e-02) (11, -4.98558755942564435504e-02) (12, 4.39462434529698312002e-02) (13, 4.66762816038173572464e-03) (14, -8.86403346604158481892e-02) (15, -6.12946428178942487319e-02) (16, -1.95414957708343189902e-03) (17, 5.43442647620180838142e-02) (18, -5.61337540840171761447e-02) (19, 2.95997375376483365383e-02) (20, -7.73778265696439954135e-02) (21, 1.54514908299072176168e-02) (22, 8.13650893995924023860e-02) (23, -6.33693698923195741779e-02) 
