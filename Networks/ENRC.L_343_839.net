FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -7.45032639790071726793e+01) (3, 8.26269112594635771529e+02) (4, 1.48498821533170200837e+02) (5, 4.60025466983539956800e+02) (6, -1.50000000000000000000e+03) (7, -3.93785449302678728145e+02) (0, -1.43336825610957930621e+03) (1, -4.98155191096940882289e+02) (2, 7.30668444964979073575e+01) (3, -3.89799717327829796432e+02) (4, 1.50000000000000000000e+03) (5, 1.50000000000000000000e+03) (6, -8.88431276338657593961e-01) (7, 1.15989849867052635091e+03) (0, 5.39824848919454858276e+00) (1, -1.23543881724630661978e+01) (2, -6.81875318785095974050e+00) (3, 8.40523128791643792113e+00) (4, 2.88410356720519756024e+00) (5, 5.32278427028189682346e+00) (6, 1.10020084613184856437e+01) (7, -1.50491860459923820770e+01) (0, -5.09835114512858034175e+00) (1, 1.29221432614073634682e+01) (2, -3.82768291629095287476e+01) (3, 4.50421290359708095252e+01) (4, 2.30372984664110873609e+01) (5, -2.79727657471729784788e+01) (6, -2.37674894951754156480e+00) (7, -1.63627903060347215103e+01) (0, 8.29757945065769386694e-01) (1, -4.79892929276985213960e+01) (2, -6.51005117131801966934e+01) (3, 7.99534223395271368418e+01) (4, 1.51149403354936453070e+02) (5, 9.09639037559389329601e+00) (6, 6.82948900175743744967e+01) (7, -5.80388054207245716043e+01) (0, -1.50000000000000000000e+03) (1, -1.38245181169377951846e+03) (2, 7.59469655234360971008e+02) (3, 1.08535544675347659904e+03) (4, -5.34193700227935210023e+02) (5, 1.87919617999356347582e+02) (6, -1.50000000000000000000e+03) (7, -8.36288823143401316429e+01) (0, 1.68306212298083494261e+02) (1, -3.85205914934465113220e+02) (2, -3.47694064798636404134e+01) (3, -6.65666547784969537815e+01) (4, -1.49999763480933688697e+03) (5, 1.50000000000000000000e+03) (6, 5.85215550361216685360e+01) (7, -6.00885872977968574560e+02) (0, -5.53080247664904049998e+01) (1, 4.80352503346959665009e+01) (2, -1.47379159152893564055e+01) (3, -1.09982809444981803892e+01) (4, -8.75725776464164518131e+00) (5, 2.56784054374560444245e+00) (6, 1.95036171862798610732e+01) (7, 2.66725645805676192523e+00) (0, 1.35626704077718017061e+02) (1, -9.41564721594074001132e+01) (2, 7.67821164964841074152e+00) (3, -1.10898992118061826773e+02) (4, 1.30705006108385148877e+01) (5, -1.62940923647817825781e+01) (6, -1.04782017069302753498e+02) (7, 6.28135686551855556559e+01) (0, -1.03465782106598680912e+02) (1, 3.64984277813094166731e+01) (2, 4.56136281572912594129e+02) (3, -4.09888264797021918184e+02) (4, 6.48237719903999760618e+01) (5, -7.28546628740686372794e+01) (6, -1.23049511194211305565e+02) (7, -8.20767493336217235367e+00) (8, 1.21550031095902255629e+00) (9, 2.23513326226200037539e+00) (10, -5.80636310989459403231e+00) (11, 1.58915597607772385302e+00) (12, -2.40048498691712985931e+00) (13, 2.79489577886023576880e-01) (14, 1.94648295175030949800e+00) (15, -3.07639689822760020732e+00) (16, -9.22131979272710955442e-01) (17, 1.59162065490325099759e+00) (18, 1.05446605705426854627e-01) 
