FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.31914484551041914528e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, 1.45393200327894828661e+03) (6, -7.33165469582603691379e+02) (7, 7.30860679166081922631e+02) (0, -3.34973028035124613666e+01) (1, 2.25008987147066932266e+01) (2, -2.04047129024986375612e+01) (3, -1.40449549970681908384e+00) (4, -1.61392675422398852447e+01) (5, 1.43155162508204885086e+01) (6, 6.41895035979296935125e+00) (7, 5.03998518994950828187e+00) (0, 6.88105990306761228226e-01) (1, 4.74291101844824325440e+00) (2, -1.42661518969346143848e+01) (3, 1.70778150199018874389e+01) (4, -9.17383846666067270803e+00) (5, -4.38898895592332838334e+00) (6, -7.58768850822124640843e-01) (7, 2.19123114234248128618e-01) (0, 1.37042646331291166462e+02) (1, -1.49974739391987509407e+03) (2, -1.49998683782144644283e+03) (3, -1.16360996135579921429e+03) (4, -1.08568218321131382709e+02) (5, -1.23800069867544698354e+03) (6, 3.51022858877716942061e+02) (7, 1.48895251598688219019e+03) (0, -2.88424888037871198776e+01) (1, 4.48170218306383887352e+01) (2, 5.14744106575034336970e+01) (3, 1.24259128092794117748e+01) (4, -2.92173091701480869276e+00) (5, -9.28892194084470474991e+01) (6, -4.07668256354793214769e+01) (7, -6.69687032970940698817e+00) (0, 5.96419182795603219915e+01) (1, 6.62272875083575307542e+00) (2, 7.28259226130804080412e+01) (3, -4.83617607158076836527e+01) (4, -1.40421839380293764776e+01) (5, -4.00692022577728437227e+01) (6, -5.22700989068268171422e+01) (7, 2.65222219062369681808e+01) (0, -1.85213289543728976128e+01) (1, -2.12324082167697980594e+01) (2, -6.51814962842424421297e+01) (3, -2.99208952226397428831e+01) (4, -2.82837751089454698672e+01) (5, -3.24955768973094052399e+01) (6, 4.55944873864852198153e+01) (7, 3.69668209900032493920e+01) (0, -3.90653388409115294166e+01) (1, -2.20527903753257334074e+02) (2, 6.16453815258309646197e+02) (3, -6.84158887616589822755e+02) (4, 7.03754263790519189570e+02) (5, 1.51487487234123356927e+01) (6, 3.66530873245806319005e+01) (7, -5.63658827527672130486e+01) (0, 1.49454379053363390994e+03) (1, -1.10219712964535619903e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -1.49093860039557080199e+03) (5, 1.50000000000000000000e+03) (6, -1.19513319554566905367e+02) (7, -5.81688439869955260519e+01) (0, -3.00587232138847362251e+01) (1, 1.85227960418170027879e+01) (2, -3.15795948881808534736e+01) (3, 1.13638378083122759676e+00) (4, -1.37929747735258985131e+01) (5, 1.21306790118329281825e+01) (6, -6.70907490046620869073e-01) (7, 9.86435503576297634254e+00) (8, 6.57470567007962980455e+00) (9, -1.18573348274331262786e+01) (10, -3.14032881197211688473e+00) (11, 2.73751072176724541407e+00) (12, 1.16672411808535514410e+00) (13, 1.85969711699063933175e+00) (14, -3.22647660452532258901e+00) (15, -1.76596145131432114006e+00) (16, 7.44553316192526715156e+00) (17, 7.29746992898222224255e+00) (18, 3.92765389481151860895e-01) 
