FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+03) (1, -1.29833907602190720354e+03) (2, -1.12676191265159604882e+03) (3, 2.33073917325370558729e+02) (4, 1.18492956335226881492e+03) (5, 8.44534772262471733484e+02) (6, -1.50000000000000000000e+03) (7, -4.08335000635439229200e+01) (0, -2.70995019194428721221e+01) (1, 1.84355871391005443627e+01) (2, -7.04876282225190493591e+01) (3, 1.18014990503732988714e+02) (4, 1.25236431771640024380e+01) (5, -1.76851698625089461814e+01) (6, -2.05571303395178723861e+01) (7, -9.63997394374350946578e+00) (0, 1.50000000000000000000e+03) (1, 1.34878449849793378235e+03) (2, 9.81556733187829195231e+02) (3, -1.49006567593250724713e+03) (4, -1.00106508608754143097e+03) (5, -6.73405329837783483526e+02) (6, 1.50000000000000000000e+03) (7, -3.44958967002738887686e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.17786685264593415923e+03) (3, 9.93281888317476159500e+02) (4, -2.75179555178373618674e+02) (5, 4.13747305072227902656e+02) (6, -1.50000000000000000000e+03) (7, 2.07328266567324789094e+02) (0, -1.50000000000000000000e+03) (1, -1.38820051503252375369e+03) (2, -9.33175539693805603747e+02) (3, 6.96057735060181812514e+02) (4, 9.98618317572811747596e+02) (5, 1.25687249336186482651e+02) (6, -1.50000000000000000000e+03) (7, -8.42629331284302338645e+01) (0, 8.55510533908622750054e-02) (1, 5.31865146060706308617e+01) (2, -6.25004059635292179564e+01) (3, -1.13185395868831776056e+02) (4, 5.14028246591919000252e+01) (5, -8.27175311463686426805e+01) (6, 3.72432612007162555656e+00) (7, 2.87540771339893765912e+01) (0, 2.00354505094809489663e+01) (1, -2.70669579995815894335e+01) (2, -7.43253408394077497157e-01) (3, -3.52911078198154584129e+01) (4, -9.20584508297421244549e+00) (5, 2.00435775537448996886e+01) (6, -4.91786840287108120151e+01) (7, 2.32586221592965642913e+01) (0, -3.74672587688211308432e+02) (1, 2.91521087451798337042e+02) (2, 1.48395494706483623304e+03) (3, 7.21398012063123474036e+02) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, 1.37539530697328906683e+01) (0, 5.74775303119574942912e+01) (1, -2.99284781145732736718e+01) (2, 5.99112512426870466697e+02) (3, 2.80680936023231652143e+02) (4, -1.37476814463858488580e+02) (5, 5.29841829111800564078e+01) (6, -6.31866989898229121536e+02) (7, 1.13309956506212429872e+02) (0, -4.49687719204354095837e+02) (1, 5.20819090771458149902e+02) (2, 2.79432397576321193355e+02) (3, -8.81578889216550464880e+02) (4, -3.46550835776249783748e+01) (5, -6.37498764835587621747e+02) (6, 3.22785852613230417774e+02) (7, -1.91439519089636576155e+01) (8, 3.56096982686247176542e-01) (9, -9.28387310499689033527e-01) (10, -1.44205476403035892652e+00) (11, 7.44503860698724317935e-01) (12, 4.14553053539666316318e-01) (13, 2.08523083328491587451e+00) (14, -1.64004066053047781182e+00) (15, 1.06695872934928837061e+00) (16, 1.96933463125602825627e+00) (17, -1.14282083640218035114e+00) (18, -2.55828423745175337345e-01) 
