FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.45084037161453127673e-01) (1, -4.48263267855456515321e+00) (2, -2.04442021971887157861e+01) (3, 1.82795802589347751166e+01) (4, -7.74567262520399246739e+00) (5, -1.51025427651602299761e+01) (6, 3.37595480670393577327e+00) (7, 3.51859626484035770133e+00) (0, -8.35660787427446649644e+01) (1, 1.22188995534773738427e+02) (2, -1.48192679131981435603e+02) (3, 2.38025184641247591344e+02) (4, -2.11487659359878136911e+02) (5, -2.58170279234433719395e+00) (6, 6.08486587888168450888e-01) (7, -2.47963677735925855927e+01) (0, -5.00287941357335199655e+01) (1, 4.37722364232071541323e+01) (2, -4.00898197802723856853e+01) (3, 2.29709793957006027654e+01) (4, 1.59787730073901035333e+00) (5, -7.71488595629346352034e-01) (6, 1.79548435747215435754e+01) (7, -6.08814022272242016953e+00) (0, -2.41696963629584587352e+02) (1, 3.28495841393041587253e+02) (2, -6.49844200206953360066e+02) (3, 2.07162069829614296168e+02) (4, -7.45998711048682594082e+02) (5, -1.50000000000000000000e+03) (6, -9.57840502029536651207e+01) (7, 1.23492735491880708310e+02) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, -6.97166699739322666574e+02) (0, 7.76490994918771004762e+00) (1, -2.64910799541838004600e+00) (2, -1.14820802958712757658e+01) (3, 2.89967779024562020140e+01) (4, -1.55851404471983450151e+01) (5, -4.24471967127821585564e+01) (6, -1.33234008154879344232e+01) (7, 1.72540302372045339929e+00) (0, 7.40808422009434153210e+00) (1, -3.54337368815536235545e+00) (2, -1.31229788957256694459e+01) (3, 3.33883268498174103911e+01) (4, -1.70422113080475128299e+01) (5, -4.04614421141754974087e+01) (6, -1.20013552959850002821e+01) (7, 9.86451159345577699433e-01) (0, 1.50000000000000000000e+03) (1, 1.50000000000000000000e+03) (2, -1.51530564409314905561e+02) (3, -1.50000000000000000000e+03) (4, 9.14975728351220482182e+02) (5, 1.50000000000000000000e+03) (6, 1.50000000000000000000e+03) (7, -1.50000000000000000000e+03) (0, -3.12789259351574060020e+02) (1, -1.77803817811866707643e+02) (2, 1.31577576834241699544e+03) (3, 2.69652693924603681808e+02) (4, -6.22586720209820555283e+02) (5, -1.55647183941070380797e+02) (6, 2.37837251210158399317e+02) (7, -7.08062608522261484723e+02) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -1.50000000000000000000e+03) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, -5.83985200678201636038e+02) (8, -3.92254887260873541521e+00) (9, -1.76094415569266105059e+00) (10, -8.06109850139772099453e+00) (11, 2.41257985519661710683e+00) (12, 1.50000000000000000000e+03) (13, -1.99703827341350610425e+01) (14, 2.21765949648670428473e+01) (15, -7.48470960082021075088e-01) (16, -1.53372824581167366276e+00) (17, 1.50000000000000000000e+03) (18, 9.44193288767391392113e-01) 
