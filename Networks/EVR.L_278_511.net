FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 16 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.66765559714519162604e-02) (1, 9.56918129055471938793e-02) (2, 6.79876141136528944209e-02) (3, -2.36536472835190136887e-04) (4, -3.15277795348730544012e-02) (5, 7.32394155783863964881e-02) (6, 9.28749344181259428588e-03) (7, -7.40124723726879318875e-02) (0, -7.20910729406933764585e-02) (1, 5.92958367883538589593e-03) (2, -4.50676582018681992636e-02) (3, 2.64195729258592804101e-02) (4, -4.89621819773641414608e-02) (5, 3.79417882366744826927e-02) (6, -4.50863649336451927097e-03) (7, -9.87409845738259350778e-02) (0, -7.12875776370998637255e-02) (1, 7.63394938981457465976e-02) (2, -7.81840483201153152448e-02) (3, -6.77283223566162717599e-02) (4, -1.20556570523330103262e-02) (5, -3.85780920435203830698e-02) (6, 7.89536404081231241170e-02) (7, 5.11430318637643918644e-02) (0, 3.63806223329994349314e-02) (1, 5.28625264259059077232e-02) (2, -5.41827439022472961971e-02) (3, -1.85752608787307232907e-02) (4, -3.52015137329923094578e-02) (5, 7.57106172026785623208e-02) (6, -8.53880842832935305076e-03) (7, -3.18780682143281063334e-02) (0, 7.14024286181096368153e-02) (1, -4.05511958047925710757e-02) (2, 6.78853968029528298533e-02) (3, -6.01253524068795369706e-02) (4, -6.73117817165222870335e-02) (5, -2.28271112453507021844e-02) (6, -3.41378232894513425344e-02) (7, -3.94028530739672852579e-02) (0, 8.31024740167330688845e-02) (1, 2.07945200919288364361e-02) (2, 8.70167213420081075981e-02) (3, -6.58597094507472058389e-02) (4, -4.12636931615128002560e-02) (5, -1.74919166414725241188e-02) (6, -6.46006925344570215319e-02) (7, -1.25512693084965515355e-02) (0, -4.11524241403106380566e-02) (1, -4.27847392713239585427e-02) (2, 1.97204099181355479997e-02) (3, 4.67919202974724710020e-02) (4, 1.86371701752717777723e-02) (5, -1.32595116385744726806e-03) (6, -2.06504923574699766897e-03) (7, -4.49822088887126478318e-02) (0, -4.84634262280676589296e-02) (1, 4.37522083521218255187e-02) (2, 3.64425317226727482622e-02) (3, 1.63350615290561509974e-02) (4, 1.94628240646842684547e-02) (5, -7.20962781957727172344e-02) (6, 8.44569948979764228980e-02) (7, -9.13474880732221411472e-03) (0, -1.26474725104491758643e-02) (1, 5.23423902108131264277e-02) (2, 3.07399002759143682995e-02) (3, 2.00407473562769153363e-02) (4, -7.04847224315214293533e-02) (5, 9.66020784765791451498e-02) (6, 8.06378957724257494633e-02) (7, -8.73822499049044937314e-02) (0, 1.73965970783918622011e-02) (1, 6.76546156243177376766e-02) (2, -5.32419578655355732466e-02) (3, 7.61329055001274401793e-02) (4, -4.98373024141386400387e-02) (5, -1.78426488167442165444e-02) (6, -3.64183652984852307410e-02) (7, 9.01027493566684128945e-03) (0, 3.93726134020479442976e-02) (1, 8.33020461097664366434e-02) (2, -4.41978062569768070933e-02) (3, -4.19902179127963973149e-02) (4, -1.80239065442071300094e-02) (5, 5.37371459973923146225e-02) (6, 1.30275746886070742381e-02) (7, 3.35126687178413304458e-02) (0, -2.51064714060197924361e-03) (1, -5.05298949857040380351e-02) (2, -5.01522711500863790923e-02) (3, -8.30478245660338232348e-02) (4, -2.26261716913606428236e-02) (5, -6.56952777422260825180e-02) (6, 7.81742811676007509636e-03) (7, 6.47263573814385595462e-02) (0, 8.66471139587031702334e-02) (1, -6.14426730974416759890e-02) (2, -1.52328967524006445022e-02) (3, -8.38376099629343785047e-02) (4, -6.48405960178463913746e-02) (5, -3.45950024700910144237e-02) (6, -7.12198583777227667291e-02) (7, 5.25560025506615902113e-02) (0, -6.69403883358893891931e-02) (1, -2.44618146600099548027e-02) (2, 2.86889065606729110058e-02) (3, -1.67776892599119098470e-02) (4, 5.76955380133619480376e-02) (5, 9.22705428454360654378e-02) (6, 9.22325871658710438883e-02) (7, -2.93185007470622704950e-03) (0, 7.55725874650863826965e-02) (1, -5.19652204880896168016e-02) (2, 5.50779335026134950204e-02) (3, -4.24513204761046147873e-02) (4, -9.82280759808134285027e-02) (5, -3.18944932057632912770e-02) (6, 9.10613497318528419822e-02) (7, -7.38721538167022573340e-04) (8, 1.75756132986487900727e-02) (9, -5.90909229083496634338e-02) (10, 1.62134553859152666377e-02) (11, 9.49494430974042735727e-02) (12, -2.47861991604596196281e-02) (13, -7.59691178943085188013e-02) (14, 5.96757989887267067952e-02) (15, -3.81390865987403099302e-02) (16, -3.74117895016340754055e-02) (17, -5.55570992537900570918e-02) (18, -2.19766950715585759890e-02) (19, -2.25238402936434739532e-03) (20, 9.84789976623504786923e-03) (21, 6.80344813396704245489e-03) (22, -4.96963828756866177194e-02) (23, 4.29075130135940369103e-02) 
