FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=0
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535520000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464480000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=8 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (0, 5, 5.00000000000000000000e-001) (9, 5, 5.00000000000000000000e-001) (0, 5, 5.00000000000000000000e-001) 
connections (connected_to_neuron, weight)=(0, -5.38868474960327150000e+000) (1, -2.90105044841766360000e-001) (2, 6.87707996368408200000e+000) (3, -1.12605762481689450000e+001) (4, 1.95688171386718750000e+001) (5, 4.63070440292358400000e+000) (6, 3.01285648345947270000e+000) (7, -2.56731986999511720000e+000) (0, -1.92750322818756100000e+000) (1, 5.18985807895660400000e-001) (2, -5.44708609580993650000e-001) (3, 1.86151880770921710000e-002) (4, 5.65925478935241700000e-001) (5, -2.30869561433792110000e-001) (6, 1.73452210426330570000e+000) (7, 2.49126896262168880000e-001) (0, 3.02264738082885740000e+000) (1, -2.44872987270355220000e-001) (2, -1.59487947821617130000e-001) (3, -1.18225407600402830000e+000) (4, 1.82355499267578120000e+000) (5, -9.35542106628417970000e+000) (6, -5.29197692871093750000e-001) (7, -1.88991785049438480000e+000) (0, -2.77101445198059080000e+000) (1, 2.13870334625244140000e+000) (2, 1.87331473827362060000e+000) (3, 2.29496479034423830000e+000) (4, 1.48924016952514650000e+000) (5, 1.29957294464111330000e+000) (6, 2.70997071266174320000e+000) (7, -2.27999329566955570000e+000) (0, 2.39326842129230500000e-002) (1, 2.46063864324241880000e-004) (2, 5.46817660331726070000e-001) (3, 1.82566809654235840000e+000) (4, 1.61206677556037900000e-001) (5, 9.26333904266357420000e-001) (6, 4.31107878684997560000e-001) (7, -5.38530826568603520000e-001) (0, -6.74997568130493160000e-001) (1, -2.96050846576690670000e-001) (2, 9.79062497615814210000e-001) (3, -1.51354348659515380000e+000) (4, 2.22280859947204590000e+000) (5, 6.12565565109252930000e+000) (6, -9.39899444580078130000e-001) (7, 1.43378257751464840000e+000) (0, -1.12385523319244380000e+000) (1, -2.84073567390441890000e+000) (2, 9.90294814109802250000e-001) (3, -8.15752029418945310000e-001) (4, 1.05547666549682620000e+000) (5, -4.74384039640426640000e-001) (6, 1.47656118869781490000e+000) (7, 1.28872549533843990000e+000) (0, -9.12261390686035160000e+000) (1, 1.29011526107788090000e+001) (2, 7.89646053314208980000e+000) (3, 2.98363637924194340000e+000) (4, -6.78453636169433590000e+000) (5, 2.91641831398010250000e-001) (6, 1.86465415954589840000e+001) (7, -2.84575438499450680000e+000) (8, -1.92291879653930660000e+000) (9, -1.40387392044067380000e+000) (10, 1.01912569999694820000e+000) (11, 1.26768255233764650000e+000) (12, -1.85294997692108150000e+000) (13, 1.93614685535430910000e+000) (14, 4.48549598455429080000e-001) (15, -5.07342815399169920000e-001) (16, -4.54361140727996830000e-001) (8, 7.70046329498291020000e+000) (9, 5.29405212402343750000e+002) (10, 1.52188158035278320000e+001) (11, 1.13491516113281250000e+001) (12, -1.06402683258056640000e+000) (13, -2.31268000602722170000e+000) (14, 1.06450738906860350000e+001) (15, -1.44933242797851560000e+001) (16, 4.08947277069091800000e+000) (8, 2.24292898178100590000e+000) (9, 3.63235086202621460000e-001) (10, 2.13013362884521480000e+000) (11, 2.21497249603271480000e+000) (12, -1.97199380397796630000e+000) (13, 3.13069343566894530000e+000) (14, -3.05202126502990720000e-001) (15, -5.00288724899291990000e-001) (16, -5.09021878242492680000e-001) (8, -4.69904088973999020000e+000) (9, 2.31564903259277340000e+001) (10, 4.83747863769531250000e+001) (11, -4.90868186950683590000e+000) (12, -4.39739913940429690000e+001) (13, -3.09292736053466800000e+001) (14, 1.97050109863281250000e+002) (15, -1.86936149597167970000e+001) (16, -3.02051687240600590000e+000) (8, -8.72990417480468750000e+000) (9, 3.85911163330078120000e+002) (10, 2.11687107086181640000e+001) (11, 4.13989543914794920000e+000) (12, 6.07328376770019530000e+001) (13, -1.23021211624145510000e+001) (14, 1.30514535903930660000e+001) (15, 2.91620483398437500000e+001) (16, 3.83591914176940920000e+000) (8, -3.72779273986816410000e+000) (9, 3.70766487121582030000e+001) (10, 3.08164119720458980000e+000) (11, 2.22137470245361330000e+001) (12, -3.56201112270355220000e-001) (13, 4.88519287109375000000e+000) (14, 3.93147964477539060000e+001) (15, -6.60968732833862300000e+000) (16, -2.78312301635742190000e+000) (8, -1.51622742414474490000e-001) (9, 2.17385649681091310000e+000) (10, 2.71499824523925780000e+000) (11, 4.44273084402084350000e-001) (12, -7.90228843688964840000e-002) (13, 1.40974545478820800000e+000) (14, -1.80662608146667480000e+000) (15, 1.44673287868499760000e+000) (16, 3.83520698547363280000e+000) (8, -2.00555992126464840000e+001) (9, 2.29329528808593750000e+002) (10, -2.09655036926269530000e+001) (11, 1.04586120605468750000e+002) (12, -4.52753982543945310000e+001) (13, 5.27049398422241210000e+000) (14, 2.07042648315429690000e+002) (15, 1.04192142486572270000e+001) (16, -1.75098490715026860000e+000) (17, 2.36222419738769530000e+001) (18, 2.20431256294250490000e+000) (19, 1.25699729919433590000e+001) (20, 1.75045108795166020000e+000) (21, -4.33972263336181640000e+000) (22, -3.37581992149353030000e+000) (23, 1.14486341476440430000e+001) (24, 4.98132324218750000000e+000) (25, -6.24185204505920410000e-001) 
