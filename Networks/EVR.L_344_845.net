FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 16 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.27411086706982260019e-02) (1, 5.95795901988385515069e-02) (2, 8.27661262119729068676e-02) (3, 2.41669699425543782478e-03) (4, -4.92567593121045615989e-02) (5, -8.79001662194753424773e-02) (6, -1.47111073465810288097e-03) (7, 3.02086307512019619503e-02) (0, -7.84443166620182319448e-02) (1, 2.26405452585301536494e-02) (2, -4.74745097193793805235e-02) (3, 6.02735967043577999802e-02) (4, -8.64941377042850317869e-02) (5, -8.53721354770978491100e-02) (6, 9.17046192728671050176e-02) (7, -4.51848294799749375383e-02) (0, -6.99346052659244044047e-02) (1, -1.92181402887126803747e-02) (2, -3.54052525632866030292e-02) (3, -4.57472816407275342798e-02) (4, 9.49891123173998430662e-02) (5, 8.20335054886863201951e-02) (6, -6.32564343624775621278e-02) (7, 7.95158493074156064173e-02) (0, 4.24171033116743367852e-02) (1, 1.77885371117075807845e-03) (2, 2.29443587056451792083e-02) (3, 7.50815558259420867682e-02) (4, -3.82848704350720325795e-02) (5, -8.27050756879907089658e-02) (6, -7.33557891786960902802e-02) (7, -9.55437631613576671130e-02) (0, 7.68745160009639688647e-02) (1, -9.05896644568393027974e-02) (2, 6.87293532301389009653e-03) (3, -7.23822448012567121189e-02) (4, -7.84898291861985397677e-02) (5, -9.45981769017603391081e-02) (6, 5.78263874400613692162e-02) (7, -5.69341442649683865396e-02) (0, 2.80423698468859408650e-02) (1, -8.96481237694341237532e-02) (2, -9.66605490507267128830e-02) (3, 4.15482337258492873122e-02) (4, -7.50202577564158534784e-02) (5, 9.50440717122565253971e-02) (6, 9.63634057359904760975e-02) (7, -4.49548615322241315595e-02) (0, -2.41740700665722743623e-02) (1, -3.90418483174122532553e-02) (2, 9.29785831716445354544e-03) (3, -2.91849592392885506809e-02) (4, -5.70083443188420455061e-02) (5, 4.60414255379352696518e-02) (6, -4.96691114219890636483e-02) (7, 8.54087604829484037250e-02) (0, -5.21797222410100916545e-02) (1, 7.32752488669044937941e-02) (2, 6.04903148187743711084e-02) (3, 9.53540890716625400003e-03) (4, 9.05701746690299180909e-02) (5, 8.71345272233266521233e-02) (6, 1.39916472359247062718e-02) (7, 6.74446891798777536930e-02) (0, 9.65448642566034687107e-02) (1, -7.91354189311775230165e-02) (2, 9.50624458687371609589e-02) (3, -8.19449663265789385314e-02) (4, -7.37335943428217288620e-02) (5, 5.28888318186824177292e-02) (6, -3.88791091014311987473e-02) (7, 5.43087770873125832982e-02) (0, 6.32407095393644064218e-02) (1, -3.55396566620417853066e-02) (2, -4.14299067695424877433e-03) (3, 8.82204532730646723282e-02) (4, -4.04955864399013792942e-02) (5, -7.77958643107989900045e-03) (6, -5.67344097492755786161e-02) (7, 3.53303449836424657282e-02) (0, 5.31785667416239671290e-02) (1, 5.25634501511372531635e-02) (2, -9.38546157457622043374e-02) (3, 9.61702239128980340688e-02) (4, -1.39512580104359656952e-03) (5, -4.35237255845028897516e-02) (6, 8.15789829057303322868e-02) (7, 4.64251534480624311607e-02) (0, -7.02484782077145153423e-02) (1, 4.20692963275208428597e-02) (2, -4.40394391348874342240e-02) (3, -7.96783050288007166362e-02) (4, 2.92038220607313755983e-02) (5, 6.99522095911533914325e-02) (6, 8.77663856411931564416e-02) (7, 2.57486848272187179854e-02) (0, 9.08167921500919878008e-02) (1, 8.28288300198141980157e-02) (2, 4.38037199907559057777e-02) (3, -8.29168035897136085355e-02) (4, 3.57176603483805032990e-02) (5, -9.50753906007914123544e-02) (6, 7.13919749877151010864e-02) (7, -1.04163160237120966389e-03) (0, -3.06150457727170782762e-02) (1, -3.27510171793552740116e-02) (2, -1.28211798194226567205e-02) (3, 2.88893692774976618143e-02) (4, 5.94693978796809463727e-02) (5, 3.04444119214178840482e-02) (6, -3.57802872289759918423e-02) (7, 1.26479631311887941170e-02) (0, -1.69921394175609821731e-02) (1, -2.96349013914898179456e-02) (2, 8.81818555397071573987e-03) (3, 8.16127362715115406422e-02) (4, 2.68413745141234116875e-02) (5, -9.60283303041507135811e-03) (6, 2.80378883225901112675e-02) (7, 5.65928977965250157300e-02) (8, -6.75335381930103478831e-02) (9, 8.39984506778188033671e-02) (10, 7.69145942578404184786e-02) (11, 6.16702853578371470999e-02) (12, 5.39506588719883273253e-02) (13, 6.46809784089174555355e-02) (14, -1.25810312119279954501e-02) (15, 4.47674495319641957414e-02) (16, 4.75098069386155341665e-02) (17, -6.87773127112882021184e-02) (18, 6.18506474323667065907e-02) (19, -1.67725342031200819193e-02) (20, -6.38527017288312431775e-02) (21, 3.32426209299656813534e-02) (22, 8.21858356846248278016e-02) (23, 5.53225398856779793100e-03) 
