FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 10 10 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.42969645825501402214e+02) (1, 5.32563175924756478707e+02) (2, 1.12309954286603806395e+03) (3, -4.55435774102418065468e+02) (4, 7.77769921384763392780e+02) (5, 4.04344822512931500569e+02) (6, -6.25088414636881338993e+02) (7, -1.11363596052851653440e+03) (0, 7.30063506888129268191e+02) (1, -4.06036880083265543817e+02) (2, 1.35672801550077792854e+03) (3, -1.37803342361139311834e+03) (4, 8.10557204722934017127e+01) (5, -5.02465428168644194784e+01) (6, -5.93950625394866506213e+02) (7, 7.04320866836169869885e+01) (0, -3.17923037842582573376e+02) (1, 2.56068518039737170966e+02) (2, -8.25952077351267462291e+02) (3, 6.87678001347975509816e+02) (4, -2.69102186485402285143e+02) (5, -3.94950298158136519078e+01) (6, 2.92386332219368966889e+02) (7, 1.36959417015084341074e+02) (0, -1.12866989515834347912e+03) (1, 1.37723975470614777805e+03) (2, -4.28159278310913464338e+02) (3, 1.44205118626905164092e+03) (4, -1.47991161082064650145e+03) (5, 9.08229351057592907637e+02) (6, -1.06066733953338527385e+02) (7, -7.05134913425166445222e+01) (0, -1.31241311852560988882e+03) (1, -7.03194708390337723358e+02) (2, 3.44150998862636924969e+02) (3, 1.28100127104720991156e+03) (4, -1.35537577459160752369e+03) (5, 9.40393945079180753055e+01) (6, 1.37953920120665429749e+03) (7, 1.04801038278641854617e+02) (0, 2.31903949009969551298e+02) (1, -8.54190896918241122648e+01) (2, 7.55265318309809572384e+02) (3, 1.89302516498305550385e+02) (4, 1.16340416918808864466e+03) (5, -5.17812273463648580218e+02) (6, -9.08994050536306417598e+02) (7, -6.41926877390668515488e+00) (0, -1.30212832086478670135e+03) (1, 1.43665388114040797518e+03) (2, -8.70204989578694608099e+02) (3, -1.71417080878343739414e+01) (4, -1.98289312004229913100e+02) (5, -9.94636400655028523943e+02) (6, -1.14569586182926218498e+03) (7, 1.48911520100273469325e+03) (0, -1.51456709161484582182e+02) (1, 1.37584030617060057011e+03) (2, 1.48665243040413542985e+03) (3, -3.91772893454265499713e+02) (4, -3.73162630700023782993e+02) (5, 1.50000000000000000000e+03) (6, -1.37840808285530511057e+03) (7, -1.81018263351763351920e+02) (0, 7.32733729383628542564e+02) (1, 5.61295988008148469817e+02) (2, -3.89735082859751287288e+02) (3, 6.07456019534649129810e+01) (4, -1.03778107687056672148e+03) (5, -1.14045187224177698226e+03) (6, 3.44711751838563031924e+02) (7, -1.60421700373012811269e+02) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 1.49051729353836117298e+03) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 1.01577328539712169686e+02) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 1.34229559782750584418e+03) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 1.26395062693691602362e+03) (8, -1.35580505454736544380e+03) (9, 1.94046730907608804273e+02) (10, -1.07111249678666467844e+03) (11, 1.25093479512346971205e+03) (12, -2.33232451524401938059e+02) (13, 1.77568320276986412409e+02) (14, -1.50000000000000000000e+03) (15, -1.50000000000000000000e+03) (16, 1.30328454897615688424e+03) (17, 1.18069935520328317580e+03) (8, -1.50000000000000000000e+03) (9, -5.87830746457835306984e+00) (10, 1.49990085784414122827e+03) (11, 1.50000000000000000000e+03) (12, -1.49132322876619264207e+03) (13, -1.39968830794236487236e+03) (14, -1.49997652966283044407e+03) (15, -1.49571369848743438524e+03) (16, -1.50000000000000000000e+03) (17, 1.50000000000000000000e+03) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 3.37274878015287669086e+01) (8, -1.50000000000000000000e+03) (9, -1.50000000000000000000e+03) (10, -1.50000000000000000000e+03) (11, 1.50000000000000000000e+03) (12, -1.50000000000000000000e+03) (13, -1.29997190201472562876e+03) (14, -1.50000000000000000000e+03) (15, 1.37530673424198630528e+03) (16, -1.50000000000000000000e+03) (17, 1.00217764592313343996e+02) (8, 1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, -1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.49458009358426784274e+03) (16, 1.50000000000000000000e+03) (17, 8.97973947699163318248e+02) (18, 3.50537183933417317849e-01) (19, 3.71988824313600197069e-01) (20, 4.16722967972464497510e-01) (21, 4.54081885387867950632e-02) (22, -7.68486115032908756461e-01) (23, -5.58891002615918619512e-01) (24, 6.02566390454423311818e-02) (25, -1.04900665239271173590e+00) (26, 2.81242602824911536175e-01) (27, -1.17943564801657285734e+00) 
