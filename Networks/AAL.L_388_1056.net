FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 10 10 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+03) (1, -1.49955590026947334081e+03) (2, -1.49223662861156958570e+03) (3, -1.49115061797399380339e+03) (4, 1.46281678515990779488e+03) (5, 1.43780294473820299572e+03) (6, -1.38373045869893985582e+03) (7, 5.18703266509068384948e+02) (0, -6.15020445916472453973e+02) (1, -1.27656641937557492383e+03) (2, 1.19726013926613882177e+03) (3, -1.06990665176404763770e+03) (4, -1.13558796914881395423e+03) (5, 1.05910616829623904778e+03) (6, 5.14957352882616078205e+02) (7, 1.31839756240131146114e+03) (0, 1.38690112603182933526e+03) (1, 1.49459919756208410035e+03) (2, -5.68435635105839196513e+02) (3, -1.38429136201544952200e+03) (4, 1.38383852923474819363e+02) (5, -1.48459434032181661678e+03) (6, 1.50000000000000000000e+03) (7, 8.42966134170245936730e+02) (0, -3.66609370175148512772e+02) (1, 4.86478478706693806544e+02) (2, 1.75335084095874691457e+02) (3, -1.50832395595726296733e+02) (4, 2.12422873794520285173e+02) (5, -3.44360650609957232859e+01) (6, -5.28404880635434551550e+02) (7, 1.63774942063930495806e+02) (0, 5.17597250793041467887e+01) (1, -4.44963965661790012973e+01) (2, -4.90786131815573956061e+00) (3, 1.96107608090907814535e+00) (4, -9.13274669855515242034e+01) (5, -1.63315123924623684104e+01) (6, 1.05978808748434492060e+01) (7, -3.87165857095292675893e+00) (0, 1.49884362447511421124e+03) (1, -5.81349350696934379812e+02) (2, 1.31461484337970728120e+03) (3, -1.24832104291550717790e+03) (4, -7.15052920121367378670e+02) (5, 2.78166933009127717469e+02) (6, -8.98761043491446912412e+02) (7, 1.28278804599886342430e+02) (0, 4.49109404262989698964e+02) (1, 1.49948420942065058625e+03) (2, -5.04764796832335719046e+02) (3, -8.98612002626609637446e+02) (4, 9.23929899222545373050e+02) (5, 1.34951028261095621019e+03) (6, 3.90462653140893621639e+02) (7, -1.42336225223785550043e+03) (0, -8.76163500634511933640e+02) (1, 1.20882648646889288102e+03) (2, -1.16981711119854912795e+03) (3, 1.30585472733845389115e+01) (4, 1.18655682007401125588e+02) (5, 4.56520266110182717512e+02) (6, 1.49195955483806346820e+03) (7, -2.82554201283741406314e+02) (0, -5.99397534915287266699e+01) (1, 7.68851377802295701258e+01) (2, -8.24744929566319342484e+01) (3, 8.44268181438245051140e+01) (4, -3.28191775479647773750e+01) (5, -2.93509230905830964531e+00) (6, 2.53850943314986494670e+01) (7, -3.25225861977104846456e-01) (8, 1.15748741219787575574e+03) (9, -8.92719824789597964809e+02) (10, -1.30006134959252062799e+03) (11, 1.43573483898553536164e+03) (12, 1.50000000000000000000e+03) (13, -5.43006907101519232128e+02) (14, 4.44042428063923580339e+02) (15, -2.27866651648913567385e+01) (16, 1.45651532470289862431e+03) (17, 8.54600499785260808494e+02) (8, 1.01365001378983708946e+03) (9, 1.50000000000000000000e+03) (10, -1.22150250418791961238e+03) (11, -4.41117855364915499194e+02) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, -3.39675975442023059259e+01) (16, 1.50000000000000000000e+03) (17, -1.77996411077588049920e+02) (8, 1.48031590239086426664e+03) (9, 9.66872175220761846504e+02) (10, -1.12385960415416548130e+02) (11, -1.29563523535380841167e+03) (12, 1.50000000000000000000e+03) (13, 4.19079267161904795103e+02) (14, 2.56944415632968059526e+02) (15, -1.22732587363762448263e+02) (16, -1.09076996568493814266e+03) (17, -7.49123009953283514051e+01) (8, 1.01365001378983708946e+03) (9, 1.35785871664136107029e+03) (10, -1.39995590312093486318e+03) (11, 1.22093706734432271332e+03) (12, 1.49933729481335194578e+03) (13, -1.25299629986436252693e+03) (14, 1.50000000000000000000e+03) (15, 1.46452061048630321238e+03) (16, 1.93707093490299314453e+02) (17, -2.75860898489512351262e+02) (8, 1.06446960384256590260e+03) (9, 1.43460302215221054212e+03) (10, -5.89289794900933543431e+02) (11, -1.23854772017342793333e+03) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, -3.32057945417003679722e+02) (16, 1.50000000000000000000e+03) (17, -2.69291981903387807051e+02) (8, -1.02341498019938740072e+03) (9, 1.14702603907293723751e+03) (10, -7.97469607380491311233e+02) (11, -4.71164448467195427384e+02) (12, -1.50000000000000000000e+03) (13, -1.01715377488725391686e+03) (14, -3.93277109993727094661e+02) (15, 1.49832688847666986476e+03) (16, -1.50000000000000000000e+03) (17, 1.49993388432660776743e+03) (8, 1.26258022598060256314e+03) (9, -7.89417660883096118596e+02) (10, -7.72316538250633357165e+02) (11, 3.25941460877097370030e+02) (12, 1.50000000000000000000e+03) (13, 1.50000000000000000000e+03) (14, -7.03723581005966991597e+01) (15, 2.28645726360434622393e+02) (16, 1.50000000000000000000e+03) (17, -5.52544288743316087675e+01) (8, 1.44846043816004180371e+03) (9, 1.44887253871066286592e+03) (10, -1.48712937545284376029e+03) (11, -1.31968474473153082727e+03) (12, -1.50000000000000000000e+03) (13, -1.50000000000000000000e+03) (14, -2.67919147973952476605e+02) (15, -1.45690451936010958889e+03) (16, -1.50000000000000000000e+03) (17, 1.36363635771372287309e+03) (8, -5.57468234177025010467e+02) (9, -3.59854193815220355646e+02) (10, -6.52921240155144346318e+02) (11, 1.51901265674154153373e+01) (12, -1.50000000000000000000e+03) (13, 4.52129704509276741931e+00) (14, 8.49721819058067353581e+02) (15, -9.99416445889441092731e+02) (16, 1.13912185998722952718e+03) (17, 3.22412860902156097609e+01) (18, -4.87829525964847798836e-01) (19, -4.68880912117771650460e-02) (20, -4.12383912698328913837e-01) (21, -4.22822221523602326254e-01) (22, -4.82515594918477230824e-01) (23, 3.75481365749565865197e-01) (24, -6.22104916038768607223e-01) (25, 5.79381880614520339279e-01) (26, 1.32453835069356012921e-01) (27, 1.71130345500077662990e+00) 
