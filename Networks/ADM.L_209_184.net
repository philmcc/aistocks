FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.98691321438499031160e+01) (1, -1.84853617429316443577e+01) (2, 6.66760809860720726761e+00) (3, 3.90046909515342621333e+00) (4, -1.39754276387276359372e+01) (5, 3.18776598296148527822e+00) (6, -1.63790216957351297822e+01) (7, -1.11815416032986743033e+01) (0, -5.63080378444608009580e-01) (1, 1.11704630916390645901e+00) (2, -3.92388139816000558469e+00) (3, 3.19642437595417605589e-01) (4, 9.45739784260644866798e-01) (5, -2.20123640964182998303e+00) (6, 5.01439560960358310382e+00) (7, -2.59610447532970800566e-01) (0, -2.04524996674306919431e+02) (1, 1.72093482034085127452e+02) (2, 2.99636622647765804572e+01) (3, 2.53798226586326265419e+01) (4, 1.11457978133439937096e+02) (5, -1.70894329390885133080e+02) (6, 1.12933123216344952766e+02) (7, -2.25948002051063028262e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -6.53743314191594663498e+02) (4, 7.63253059963458611037e+01) (5, 6.08505143065531115099e+02) (6, 3.65557945542972561270e+02) (7, -1.16341620894948690079e+02) (0, 1.02790466692435373375e+02) (1, -3.20951997721431965260e+01) (2, -5.75869996315994399083e+01) (3, 3.49452973850738004558e+01) (4, 1.42593692795158464293e+01) (5, -1.64399075703648861690e+02) (6, -2.71176881791926724929e+01) (7, 1.67110489607166492476e+01) (0, 2.26010371980957387450e+01) (1, -1.05583493040947242747e+01) (2, -1.34955203933806213712e+01) (3, 2.05656080013061028922e+01) (4, -4.11733154008313988470e+01) (5, -4.30481141208719808589e+00) (6, 4.97517635101087396521e+00) (7, -1.80610542793305595133e+00) (0, 1.01362377930654406555e+03) (1, 1.50000000000000000000e+03) (2, 1.50000000000000000000e+03) (3, 6.30551682094278476143e+02) (4, -1.50000000000000000000e+03) (5, -1.34247030811896001978e+03) (6, -1.50000000000000000000e+03) (7, -1.42109618174122101664e+03) (0, -3.21722783808254142457e+00) (1, 4.43282527293475752117e+01) (2, -2.63871008822472212785e+01) (3, 3.67545881149082447337e+01) (4, -6.22726423837862128607e+01) (5, 1.25489922757647804019e+02) (6, -1.89567281228040833696e+01) (7, -1.96000121406967870996e+01) (0, 3.00282429830484893785e+01) (1, 1.58307313572846020122e+01) (2, 2.40879297225481003863e+01) (3, -3.80845553696314951253e+01) (4, -7.65977363091506617820e+01) (5, -2.80774383313016038244e+01) (6, -1.11348104711050481797e+01) (7, -5.28788423350407210677e-01) (0, 5.75995982560418383400e+02) (1, -1.02713296673389777425e+03) (2, -4.81358707199346554262e+02) (3, 1.78226084855715242838e+02) (4, -5.17706217211156285884e+02) (5, 8.11294051634896788983e+01) (6, 1.50000000000000000000e+03) (7, 2.04121515563595856690e+01) (8, 5.43383150824140059854e+00) (9, -3.72903844176347076811e+00) (10, 1.38093987356871950034e+00) (11, 1.87116277011817899734e+00) (12, 3.22559620932717194819e+00) (13, -5.15508920444346330214e+00) (14, -4.62634908970254776772e-01) (15, 2.73421852736160531094e+00) (16, 4.71028259982211139345e+00) (17, 1.32576309858202967540e+00) (18, -2.45123997890613631867e+00) 
