FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 10 10 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (10, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.37572231448533693765e+03) (1, 1.36939721374664418363e+03) (2, 6.15877692595068197079e+02) (3, 1.48484248171670719785e+03) (4, -1.46677386484912494780e+03) (5, 1.46072689070372416609e+03) (6, -1.41696062974063056572e+03) (7, -1.02494805985839752793e+03) (0, 2.85245508618132475931e+02) (1, -1.37039612500504404125e+03) (2, 5.49019144341883560401e+01) (3, -8.92233278421392697055e+02) (4, -1.49700880532038854653e+03) (5, 1.45518797700026789244e+03) (6, 1.49498869882859003155e+03) (7, 6.85747684628423371578e+02) (0, 1.27463203717532246628e+03) (1, 1.31243842670132812600e+03) (2, -1.13749867474853726890e+03) (3, 1.82678196162504349331e+02) (4, -1.49418747529622282855e+03) (5, 1.56966184977381971066e+02) (6, 1.80961753200656715990e+02) (7, -9.68139337008218262781e+02) (0, 6.79812238020456447884e+02) (1, -5.70996592187679425479e+02) (2, -1.03618925037651877119e+02) (3, -1.46217746432767194165e+03) (4, 1.03445016964695355455e+02) (5, -7.53156562173948316286e+01) (6, 1.43540620850797472485e+03) (7, 2.73071524389182684445e+02) (0, -4.92904116092482411204e+02) (1, -2.69612667477584807330e+02) (2, 7.35991532286488450154e+02) (3, 5.19698372458365838611e+02) (4, -1.58049209839450497839e+02) (5, 1.11598500343366708876e+02) (6, -5.48800987338032996377e+02) (7, 1.82996287420599031748e+02) (0, -1.12952208767857541716e+03) (1, 1.40857434216433671281e+03) (2, -1.26695104943335809367e+03) (3, -5.10812064787039687985e+01) (4, 4.05760889286776489371e+02) (5, -6.46608768499175710076e+01) (6, 1.31795368688846315308e+03) (7, -8.74782787454943218108e+02) (0, -8.50866247130857232150e+02) (1, -5.68385482800474505893e+02) (2, -1.48088648585556870785e+03) (3, 5.29519170843428923945e+02) (4, 1.35679107378997309752e+03) (5, -3.76212152963857477062e+02) (6, 1.35854466343046215115e+03) (7, 4.02396648318627967456e+01) (0, -7.52886104319964942988e+02) (1, 6.71539496847565686721e+01) (2, -2.39704029498261633080e+02) (3, 5.48996735937279709105e+02) (4, -6.07421608770095417640e+02) (5, 3.67238827036079385380e+02) (6, 5.55732732660786609813e+02) (7, 7.28446993389093222504e+01) (0, -8.68347306944658384964e+02) (1, -7.39879778409791128979e+02) (2, 7.77541965359986534168e+02) (3, -1.12516755502376986442e+03) (4, -1.00891941364285753480e+03) (5, 2.01908198876020406942e+02) (6, 8.07803522908025342986e+02) (7, 1.02494723712157269802e+03) (8, -7.85559515810958259863e+02) (9, -9.48079119597563817479e+02) (10, 9.83471866680452990295e+02) (11, -1.46084109803296428254e+03) (12, -8.82603267154465584099e+02) (13, 1.24442997240583122220e+03) (14, -6.22585083021199849895e+01) (15, -4.59511937079128813366e+02) (16, 1.45153316777049076336e+03) (17, 1.42176694757430209393e+03) (8, 7.04979547012566513331e+02) (9, 1.00537510421343802136e+03) (10, -4.35614849459276229027e+02) (11, -1.17816399971680070280e+01) (12, -4.37584765712019475359e+02) (13, 1.46857774389882911237e+03) (14, 1.00064904127942406831e+03) (15, -1.00906427418972702981e+03) (16, -1.02514035697431108929e+03) (17, 4.66635685139154759327e+02) (8, 1.11802849222323425238e+03) (9, -1.33655501711528950182e+03) (10, -1.47137968300110514974e+03) (11, 1.33754284214887638882e+03) (12, -1.11956421907672734051e+03) (13, -1.49149107996620023187e+03) (14, -1.49308266849126061970e+03) (15, 1.50000000000000000000e+03) (16, 1.12977069065444948137e+03) (17, 1.49999954712564999681e+03) (8, -2.48058763328070654097e+02) (9, -4.90037541898426070475e+02) (10, -8.65186087441643962848e+02) (11, -1.61591759056537995320e+02) (12, 9.25145459547465804917e+01) (13, 1.46857774389882911237e+03) (14, -8.29691799822989082713e+02) (15, 8.26347051439955976093e+02) (16, 5.09684928772733769620e+01) (17, 6.90992731825266332635e+02) (8, 8.77527924688762261951e+00) (9, -6.41317472159331373405e+02) (10, 6.01976477585027737405e+02) (11, -9.07084632376991521596e+02) (12, -3.99444981087493147243e+02) (13, -1.36368653417821701623e+03) (14, -9.62499806892254383683e+00) (15, 9.59853089745409988609e+02) (16, 6.04014668371862512686e+02) (17, 3.68550630139794463958e+02) (8, -5.92047481575736355808e+02) (9, -1.43514940490588696775e+03) (10, -1.31258203616436207994e+03) (11, -6.63020327341875503890e+00) (12, -8.06329347096494984726e+02) (13, 1.25403625162669527526e+03) (14, 1.44149016556030193925e+01) (15, -7.39157050330743903288e+00) (16, 1.26494252505543613552e+03) (17, 1.49999823663461666001e+03) (8, 1.06803553331374837398e+03) (9, -1.47102461225434922198e+03) (10, -2.27994552871412707873e+02) (11, 1.63074523823754958585e+02) (12, 3.55984719840016566650e+02) (13, -1.36368653417821701623e+03) (14, 2.30251096704801341275e+02) (15, 1.50000000000000000000e+03) (16, -1.48611694047245396177e+03) (17, 8.94527254329936226895e+02) (8, 7.66026349221272425893e+02) (9, -1.29070918142575055754e+03) (10, 1.42360847246497723972e+03) (11, -1.41248915048765138636e+03) (12, 1.42996830366563199277e+03) (13, 1.27980068885631453668e+03) (14, -7.53234347986858665536e+02) (15, 5.39779500384954417314e+02) (16, 1.38674829621714411587e+03) (17, 7.81500257629297379935e+02) (8, 9.09023306178237362474e+02) (9, -2.76300277373403035952e+00) (10, 1.45744978575611935412e+03) (11, -1.44846761513618889694e+03) (12, 1.42535366713364760471e+03) (13, 1.42781904914621441094e+03) (14, 1.43032545735081725979e+03) (15, -2.66330545065037007646e+01) (16, 1.49769389871133444103e+03) (17, -1.47387421830503762976e+03) (18, -1.10118635507190518186e-01) (19, -2.78184524489375362144e-01) (20, 2.52518070453549903220e-01) (21, -2.67439884021546947501e-01) (22, 3.47159381332022953792e-01) (23, 3.75094649885259534550e-01) (24, 3.30426110018900376364e-01) (25, -2.96269126726464215871e-01) (26, -1.09551407970674377634e-01) (27, -4.89562946644571880817e-02) 
