FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (8, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.43570218225058710004e+01) (1, -2.29001113136349516708e+02) (2, 1.44611052920977956049e+00) (3, 4.87684582221851883332e+02) (4, -4.21770153310416446857e+01) (5, -3.04499088931896686461e+01) (6, -6.13253126417535021631e+00) (7, 3.09218859901090539211e+01) (0, 9.59190353312038155309e+01) (1, -7.03038814903143531865e+01) (2, -1.30737731420176412911e+01) (3, -1.02632862584784980697e+01) (4, -3.10242601455765321106e+00) (5, -3.65810431308428292141e+01) (6, -4.19418735984817629969e+01) (7, 1.16510148987177242219e+01) (0, 1.43717082910745030944e+01) (1, 1.01512913908498632054e+01) (2, -2.92525319198841700086e+01) (3, 1.68863733272408715891e+01) (4, -4.06171061969223217147e+01) (5, 1.18395256463010287717e+01) (6, 2.90465446189917564368e+01) (7, 2.45239367382346031832e+01) (0, -1.43355116763078143549e+02) (1, -9.14748647008054263097e+01) (2, 1.50000000000000000000e+03) (3, -1.07406932240983724114e+03) (4, -1.94301995868254152811e+02) (5, 1.98968257001770041370e+02) (6, -3.92726628830494519207e+02) (7, 9.48678938746360600476e+00) (0, 9.36963565563814326786e-01) (1, 1.11925961665798141098e+02) (2, -6.12711867679692900879e+01) (3, -1.96418971280088747733e+01) (4, 1.35260318116561020219e+01) (5, -1.58990483171334844315e+01) (6, 3.14214528283855223378e+01) (7, -5.35775182239296583475e+01) (0, -1.50000000000000000000e+03) (1, -1.50000000000000000000e+03) (2, -1.50000000000000000000e+03) (3, -1.50000000000000000000e+03) (4, -5.34050089843722503247e+02) (5, 1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, -3.44280575995850540494e+02) (0, 2.04920039002964841757e+02) (1, -2.58917289066582497981e+02) (2, 4.28851605876568328313e+02) (3, -1.27570533596472415638e+02) (4, -1.07716725084959921332e+03) (5, -1.50000000000000000000e+03) (6, 1.77683237880323162017e+02) (7, -4.26973829229872080759e+02) (0, 2.86935850000819016259e+02) (1, -3.00954687145424543360e+02) (2, 1.22845075116289081052e+02) (3, 8.01127932726516576167e+01) (4, -7.79447364749191706323e+02) (5, -1.50000000000000000000e+03) (6, -6.66475307542938963934e+01) (7, -1.67404740062966013170e+01) (0, -1.37172688437416752549e+02) (1, 3.51569444447488308469e+01) (2, 7.94188349567118621053e+01) (3, -6.83644880632557914169e+01) (4, 7.42696130489867840652e+01) (5, -2.88859084144943132344e+01) (6, 5.04191657622987747800e+01) (7, -1.14283285605232070026e+01) (0, -3.64413377956154462822e+01) (1, 6.77022548692314813934e+01) (2, 4.95575398642949949135e+01) (3, -1.17194073307496381631e+02) (4, 1.27080611921397803599e+01) (5, 8.05240270329242413538e+00) (6, 4.18620068327234235994e+01) (7, -3.99362271668042367878e+01) (8, -1.15414397381674760368e+00) (9, 1.10705341599391893226e+00) (10, 2.09649177687365773082e+00) (11, 5.24389010839366953576e-01) (12, 6.90768878087419269107e-01) (13, 8.26303393504562722072e-01) (14, -3.20699589712915844597e-01) (15, -5.27088679421932382319e-01) (16, 6.18474480585129327004e-01) (17, -1.40310183253100140277e+00) (18, -1.34549349113675842382e+00) 
